# AI-Week7
# Part 1: Theoretical Understanding (30%)
# 1. Short Answer Questions

Q1: Define algorithmic bias and provide two examples of how it manifests in AI systems.

Q2: Explain the difference between transparency and explainability in AI. Why are both important?

Q3: How does GDPR (General Data Protection Regulation) impact AI development in the EU?

# 2. Ethical Principles Matching

Match the following principles to their definitions:

A) Justice

B) Non-maleficence

C) Autonomy

D) Sustainability

Ensuring AI does not harm individuals or society.

Respecting users’ right to control their data and decisions.

Designing AI to be environmentally friendly.

Fair distribution of AI benefits and risks.



# Part 2: Case Study Analysis (40%)
# Case 1: Biased Hiring Tool

Scenario: Amazon’s AI recruiting tool penalized female candidates.

Tasks:

Identify the source of bias (e.g., training data, model design).

Propose three fixes to make the tool fairer.

Suggest metrics to evaluate fairness post-correction.

# Case 2: Facial Recognition in Policing

Scenario: A facial recognition system misidentifies minorities at higher rates.

Tasks:

Discuss ethical risks (e.g., wrongful arrests, privacy violations).

Recommend policies for responsible deployment.

# Part 3: Practical Audit (25%)
Task: Audit a Dataset for Bias

Dataset: COMPAS Recidivism Dataset.

Goal:

Use Python and AI Fairness 360 (IBM’s toolkit) to analyze racial bias in risk scores.

Generate visualizations (e.g., disparity in false positive rates).

Write a 300-word report summarizing findings and remediation steps.

Deliverable: Code + report.

# Part 4: Ethical Reflection (5%)

Prompt: Reflect on a personal project (past or future). How will you ensure it adheres to ethical AI principles?

Bonus Task (Extra 10%)

Policy Proposal: Draft a 1-page guideline for ethical AI use in healthcare. Include:

Patient consent protocols.

Bias mitigation strategies.

Transparency requirements.
